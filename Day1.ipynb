{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devdc142196/python/blob/main/Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpmbKqI7jltH",
        "outputId": "0ec1bf68-5f68-4ec7-f746-ea081ec8cab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "# Create a Spark session\n",
        "spark =SparkSession.builder.appName(\"dev\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "(1,10),(2,20),(3,30),(4,40),(5,50)\n",
        "]\n",
        "columns=[\"id\",\"value\"]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data,columns)\n",
        "# Show the DataFrame\n",
        "df.show()\n",
        "x=df.count()\n",
        "\n",
        "print(\"number of rows in above  dataframe is:\",x)\n",
        "\n",
        "#sum\n",
        "\n",
        "sm=df.select(sum(\"value\").alias(\"sum\"))\n",
        "sm.show()\n",
        "avg=df.select(avg(\"value\").alias(\"avg\")).show()\n",
        "#max\n",
        "mx=df.select(max(\"value\").alias(\"max\")).show()\n",
        "#min\n",
        "mn=df.select(min(\"value\").alias(\"min\")).show()\n",
        "#cnt\n",
        "mn=df.select(count(\"value\").alias(\"count\")).show()\n",
        "\n"
      ],
      "metadata": {
        "id": "34ZbDQBAxLWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0aafa08-14ed-4894-aa1a-9156fea3902c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id|value|\n",
            "+---+-----+\n",
            "|  1|   10|\n",
            "|  2|   20|\n",
            "|  3|   30|\n",
            "|  4|   40|\n",
            "|  5|   50|\n",
            "+---+-----+\n",
            "\n",
            "number of rows in above  dataframe is: 5\n",
            "+---+\n",
            "|sum|\n",
            "+---+\n",
            "|150|\n",
            "+---+\n",
            "\n",
            "+----+\n",
            "| avg|\n",
            "+----+\n",
            "|30.0|\n",
            "+----+\n",
            "\n",
            "+---+\n",
            "|max|\n",
            "+---+\n",
            "| 50|\n",
            "+---+\n",
            "\n",
            "+---+\n",
            "|min|\n",
            "+---+\n",
            "| 10|\n",
            "+---+\n",
            "\n",
            "+-----+\n",
            "|count|\n",
            "+-----+\n",
            "|    5|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''''a=int(input(\"enter first numner:\"))\n",
        "b=int(input(\"enter second numner:\"))\n",
        "sum = a+b\n",
        "print(\"sum of entered numbers is:\",sum)'''\n",
        "\n",
        "for i in range(1,11):\n",
        "    print(i)\n",
        "\n",
        "for x in (\"hello\"):\n",
        "  print(x)\n",
        "\n",
        "for x in (\"hello\",\"hi im dev\"):\n",
        "  print(x)\n",
        "\n",
        "z=[1,'dev','c']\n",
        "for c in z:\n",
        "  print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbmLMt96oiOj",
        "outputId": "667bba72-01c9-48f0-f377-4baf00f94a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "h\n",
            "e\n",
            "l\n",
            "l\n",
            "o\n",
            "hello\n",
            "hi im dev\n",
            "1\n",
            "dev\n",
            "c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3,20,3):\n",
        "  print(i)\n",
        "\n",
        "list(range(10))\n",
        "list(range(1,10))\n",
        "list(range(-6,10))"
      ],
      "metadata": {
        "id": "aMhzVdxEzVQu",
        "outputId": "4c02cfb9-172b-434d-91fb-0431222b0ddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "6\n",
            "9\n",
            "12\n",
            "15\n",
            "18\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = [1, 2, 3, 4, 5]\n",
        "total = 0\n",
        "\n",
        "for i in numbers:\n",
        "  total = total + i\n",
        "print(total)\n",
        "\n",
        "for i in range(2,5):\n",
        "  for j in range(i):\n",
        "    print(\"*\",end=\"\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "UESyUrsUhiAB",
        "outputId": "094e6f25-3358-4d2f-b8a1-960ccfb5891a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "**\n",
            "***\n",
            "****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Create a Spark session\n",
        "spark =SparkSession.builder.appName(\"dev\").getOrCreate()\n",
        "# Sample DataFrames\n",
        "emp_data = [ Row(emp_id=1, emp_name=\"Alice\", emp_salary=50000, emp_dept_id=101, emp_location=\"New York\"),\n",
        "             Row(emp_id=2, emp_name=\"Bob\", emp_salary=60000, emp_dept_id=102, emp_location=\"Los Angeles\"),\n",
        "             Row(emp_id=3, emp_name=\"Charlie\", emp_salary=55000, emp_dept_id=101, emp_location=\"Chicago\"),\n",
        "             Row(emp_id=4, emp_name=\"David\", emp_salary=70000, emp_dept_id=103, emp_location=\"San Francisco\"),\n",
        "             Row(emp_id=5, emp_name=\"Eve\", emp_salary=48000, emp_dept_id=102, emp_location=\"Houston\") ]\n",
        "dept_data = [Row(dept_id=101, dept_name=\"Engineering\", dept_head=\"John\", dept_location=\"New York\"),\n",
        "             Row(dept_id=102, dept_name=\"Marketing\", dept_head=\"Mary\", dept_location=\"Los Angeles\"),\n",
        "             Row(dept_id=103, dept_name=\"Finance\", dept_head=\"Frank\", dept_location=\"Chicago\") ]\n",
        "\n",
        "emp_columns = [\"emp_id\", \"emp_name\", \"emp_salary\", \"emp_dept_id\", \"emp_location\"]\n",
        "dept_columns = [\"dept_id\", \"dept_name\", \"dept_head\", \"dept_location\"]\n",
        "emp_df = spark.createDataFrame(emp_data, emp_columns)\n",
        "dept_df = spark.createDataFrame(dept_data, dept_columns)\n",
        "\n",
        "# Display emp data print(\"emp_data:\")\n",
        "emp_df.show()\n",
        "# Display dept data print(\"dept_data:\")\n",
        "dept_df.show()"
      ],
      "metadata": {
        "id": "5lMqxqSIlS3Y",
        "outputId": "d02f257a-c277-4434-9653-df6ead21e7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+----------+-----------+-------------+\n",
            "|emp_id|emp_name|emp_salary|emp_dept_id| emp_location|\n",
            "+------+--------+----------+-----------+-------------+\n",
            "|     1|   Alice|     50000|        101|     New York|\n",
            "|     2|     Bob|     60000|        102|  Los Angeles|\n",
            "|     3| Charlie|     55000|        101|      Chicago|\n",
            "|     4|   David|     70000|        103|San Francisco|\n",
            "|     5|     Eve|     48000|        102|      Houston|\n",
            "+------+--------+----------+-----------+-------------+\n",
            "\n",
            "+-------+-----------+---------+-------------+\n",
            "|dept_id|  dept_name|dept_head|dept_location|\n",
            "+-------+-----------+---------+-------------+\n",
            "|    101|Engineering|     John|     New York|\n",
            "|    102|  Marketing|     Mary|  Los Angeles|\n",
            "|    103|    Finance|    Frank|      Chicago|\n",
            "+-------+-----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Join the two DataFrames based on department ID and location\n",
        "joined_df = emp_df.join(dept_df, (emp_df.emp_dept_id == dept_df.dept_id) & (emp_df.emp_location == dept_df.dept_location), \"inner\")\n",
        "\n",
        "# Select the desired columns\n",
        "result_df = joined_df.select(\n",
        "    col(\"emp_id\"),\n",
        "    col(\"emp_name\"),\n",
        "    col(\"emp_location\"),\n",
        "    col(\"dept_name\"),\n",
        "    col(\"dept_location\")\n",
        ")\n",
        "\n",
        "# Display the results\n",
        "result_df.show()"
      ],
      "metadata": {
        "id": "WadYgPDbo6qg",
        "outputId": "7a3b164f-8d22-453d-df52-c454b39f0280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------------+-----------+-------------+\n",
            "|emp_id|emp_name|emp_location|  dept_name|dept_location|\n",
            "+------+--------+------------+-----------+-------------+\n",
            "|     1|   Alice|    New York|Engineering|     New York|\n",
            "|     2|     Bob| Los Angeles|  Marketing|  Los Angeles|\n",
            "+------+--------+------------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a PySpark query to get the average salary of employees\n",
        "# in each department, displaying dept_name\n",
        "# and the calculated average_salary.\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Join the two DataFrames based on department ID and location\n",
        "joined_df1 = emp_df.join(dept_df, (emp_df.emp_dept_id == dept_df.dept_id), \"inner\")\n",
        "joined_df1.show()\n",
        "\n",
        "df3=joined_df1.filter((col(\"dept_name\") == \"Engineering\") & (col(\"dept_head\") == \"John\") & (col(\"emp_name\")=='Alice'))\n",
        "df4=df3.drop(\"emp_dept_id\",\"dept_location\").withColumnRenamed(\"emp_salary\",\"Employee_salary\")\n",
        "df4.show()\n",
        "\n",
        "df2=joined_df1.groupBy(\"dept_name\").agg(avg(\"emp_salary\").alias(\"average_salary\"))\n",
        "# df2.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "R35N61hvqQYA",
        "outputId": "04ad1788-d628-4a67-9583-65c1b70d7526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+----------+-----------+-------------+-------+-----------+---------+-------------+\n",
            "|emp_id|emp_name|emp_salary|emp_dept_id| emp_location|dept_id|  dept_name|dept_head|dept_location|\n",
            "+------+--------+----------+-----------+-------------+-------+-----------+---------+-------------+\n",
            "|     1|   Alice|     50000|        101|     New York|    101|Engineering|     John|     New York|\n",
            "|     3| Charlie|     55000|        101|      Chicago|    101|Engineering|     John|     New York|\n",
            "|     2|     Bob|     60000|        102|  Los Angeles|    102|  Marketing|     Mary|  Los Angeles|\n",
            "|     5|     Eve|     48000|        102|      Houston|    102|  Marketing|     Mary|  Los Angeles|\n",
            "|     4|   David|     70000|        103|San Francisco|    103|    Finance|    Frank|      Chicago|\n",
            "+------+--------+----------+-----------+-------------+-------+-----------+---------+-------------+\n",
            "\n",
            "+------+--------+---------------+------------+-------+-----------+---------+\n",
            "|emp_id|emp_name|Employee_salary|emp_location|dept_id|  dept_name|dept_head|\n",
            "+------+--------+---------------+------------+-------+-----------+---------+\n",
            "|     1|   Alice|          50000|    New York|    101|Engineering|     John|\n",
            "+------+--------+---------------+------------+-------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Create a Spark session (if not already created)\n",
        "spark = SparkSession.builder.appName(\"dev\").getOrCreate()\n",
        "\n",
        "# Sample DataFrames\n",
        "customers_data = [\n",
        "    Row(customer_id=1, customer_name=\"John Doe\", city=\"New York\"),\n",
        "    Row(customer_id=2, customer_name=\"Jane Smith\", city=\"Los Angeles\"),\n",
        "    Row(customer_id=3, customer_name=\"David Lee\", city=\"Chicago\"),\n",
        "    Row(customer_id=4, customer_name=\"Sarah Jones\", city=\"Houston\")\n",
        "]\n",
        "orders_data = [\n",
        "    Row(order_id=101, customer_id=1, order_date=\"2023-10-26\", order_amount=100),\n",
        "    Row(order_id=102, customer_id=2, order_date=\"2023-10-26\", order_amount=200),\n",
        "    Row(order_id=103, customer_id=1, order_date=\"2023-10-27\", order_amount=150),\n",
        "    Row(order_id=104, customer_id=3, order_date=\"2023-10-27\", order_amount=300)\n",
        "]\n",
        "\n",
        "customers_columns = [\"customer_id\", \"customer_name\", \"city\"]\n",
        "orders_columns = [\"order_id\", \"customer_id\", \"order_date\", \"order_amount\"]\n",
        "customers_df = spark.createDataFrame(customers_data, customers_columns)\n",
        "orders_df = spark.createDataFrame(orders_data, orders_columns)\n",
        "\n",
        "customers_df.show()\n",
        "orders_df.show()\n",
        "\n",
        "dc1=customers_df.join(orders_df,customers_df.customer_id==orders_df.customer_id,\"inner\")\\\n",
        ".select(customers_df.customer_name,orders_df.order_date,orders_df.order_amount)\\\n",
        ".filter(col(\"order_amount\")>100)\n",
        "dc1.show()"
      ],
      "metadata": {
        "id": "3nCX06MUWRFy",
        "outputId": "35f074cc-cd36-4e09-ef79-52d0e96c779b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----------+\n",
            "|customer_id|customer_name|       city|\n",
            "+-----------+-------------+-----------+\n",
            "|          1|     John Doe|   New York|\n",
            "|          2|   Jane Smith|Los Angeles|\n",
            "|          3|    David Lee|    Chicago|\n",
            "|          4|  Sarah Jones|    Houston|\n",
            "+-----------+-------------+-----------+\n",
            "\n",
            "+--------+-----------+----------+------------+\n",
            "|order_id|customer_id|order_date|order_amount|\n",
            "+--------+-----------+----------+------------+\n",
            "|     101|          1|2023-10-26|         100|\n",
            "|     102|          2|2023-10-26|         200|\n",
            "|     103|          1|2023-10-27|         150|\n",
            "|     104|          3|2023-10-27|         300|\n",
            "+--------+-----------+----------+------------+\n",
            "\n",
            "+-------------+----------+------------+\n",
            "|customer_name|order_date|order_amount|\n",
            "+-------------+----------+------------+\n",
            "|     John Doe|2023-10-27|         150|\n",
            "|   Jane Smith|2023-10-26|         200|\n",
            "|    David Lee|2023-10-27|         300|\n",
            "+-------------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}