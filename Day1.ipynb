{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devdc142196/python/blob/main/Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpmbKqI7jltH",
        "outputId": "0ec1bf68-5f68-4ec7-f746-ea081ec8cab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "# Create a Spark session\n",
        "spark =SparkSession.builder.appName(\"dev\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "(1,10),(2,20),(3,30),(4,40),(5,50)\n",
        "]\n",
        "columns=[\"id\",\"value\"]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data,columns)\n",
        "# Show the DataFrame\n",
        "df.show()\n",
        "\n",
        "#sum\n",
        "\n",
        "sm=df.select(sum(\"value\").alias(\"sum\"))\n",
        "sm.show()\n",
        "avg=df.select(avg(\"value\").alias(\"avg\")).show()\n",
        "#max\n",
        "mx=df.select(max(\"value\").alias(\"max\")).show()\n",
        "#min\n",
        "mn=df.select(min(\"value\").alias(\"min\")).show()\n",
        "#cnt\n",
        "mn=df.select(count(\"value\").alias(\"count\")).show()\n",
        "\n"
      ],
      "metadata": {
        "id": "34ZbDQBAxLWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dccd6c-1fcd-4ef6-9a72-d2eb29ee41ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id|value|\n",
            "+---+-----+\n",
            "|  1|   10|\n",
            "|  2|   20|\n",
            "|  3|   30|\n",
            "|  4|   40|\n",
            "|  5|   50|\n",
            "+---+-----+\n",
            "\n",
            "+---+\n",
            "|sum|\n",
            "+---+\n",
            "|150|\n",
            "+---+\n",
            "\n",
            "+----+\n",
            "| avg|\n",
            "+----+\n",
            "|30.0|\n",
            "+----+\n",
            "\n",
            "+---+\n",
            "|max|\n",
            "+---+\n",
            "| 50|\n",
            "+---+\n",
            "\n",
            "+---+\n",
            "|min|\n",
            "+---+\n",
            "| 10|\n",
            "+---+\n",
            "\n",
            "+-----+\n",
            "|count|\n",
            "+-----+\n",
            "|    5|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "(\"HR\", 10000, 500, \"John\"),\n",
        "(\"Finance\", 20000, 1500, \"Doe\"),\n",
        "(\"HR\", 15000, 1000, \"Alice\"),\n",
        "(\"Finance\", 25000, 2000, \"Eve\"),\n",
        "(\"HR\", 20000, 1500, \"Mark\")\n",
        "]\n",
        "# Define schema\n",
        "schema = StructType([\n",
        "StructField(\"department\", StringType(), True),\n",
        "StructField(\"salary\", IntegerType(), True),\n",
        "StructField(\"bonus\", IntegerType(), True),\n",
        "StructField(\"employee_name\", StringType(), True)\n",
        "])\n",
        "# Create DataFrame\n",
        "df1 = spark.createDataFrame(data, schema)\n",
        "df1.show()"
      ],
      "metadata": {
        "id": "XbmLMt96oiOj",
        "outputId": "11cb3bbe-1ad1-46c1-ff28-f79b43ea94b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-----+-------------+\n",
            "|department|salary|bonus|employee_name|\n",
            "+----------+------+-----+-------------+\n",
            "|        HR| 10000|  500|         John|\n",
            "|   Finance| 20000| 1500|          Doe|\n",
            "|        HR| 15000| 1000|        Alice|\n",
            "|   Finance| 25000| 2000|          Eve|\n",
            "|        HR| 20000| 1500|         Mark|\n",
            "+----------+------+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}